{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ethan-code-1/project_chd/blob/main/Project_2_Coronary_Heart_Disease_WriteUp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Summary**:"
      ],
      "metadata": {
        "id": "Jo8M3nuLY7TL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Overall, this paper uses a trees model to fit a prediction on the likely 10-year coronary heart risk. Using around 10 questions we can split the data down into a prediction accuracy of XXXXXX as seen with the training set. This means that focusing on the following variables XXXXX, would help reduce the risk of coronary heart disease."
      ],
      "metadata": {
        "id": "zFh8o7wem27u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data:**\n"
      ],
      "metadata": {
        "id": "BGezdaUUmu5y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To clean the data, a number of factors were taken into account. This process started by counting and displaying all the columns with missing values, as these values can cause errors within models and leave out important missing information. To begin, a correlation matrix was created to identify variables that are highly correlated with developing coronary heart disease according to the ‘TenYearCHD’ variable. In addition, external background research was also done to get an idea of the most important variables to consider. This helped guide the cleaning process and determine what data was and was not okay to loose. Some variables that stuck out as potentially being important at this point related to predominantly to age and blood pressure.\n",
        "\n",
        "\n",
        "Lastly, the describe method was used to get a general idea of the standard deviation of each variable which came in hand when deciding the best way to impute certain missing values (using the median vs mean for example).\n"
      ],
      "metadata": {
        "id": "dDYc8mAim9zg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **first variable** cleaned was education. This variable seemed to have a low negative correlation with the ‘TenYearCHD’ variable (the lowest of the variables present within the data). Due to this, and the relatively low number of missing values, all missing values were simply set to the mean for education field (the value ‘2’)."
      ],
      "metadata": {
        "id": "uBm3du15nAmw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **second variable** cleaned was ‘cigsPerDay’. This variable is heavily influenced by the ‘currentSmoker’ variable as individuals who do not smoke should have a value of zero for this field. As a result, all individuals with a ‘0’ for currentSmoker were also set to smoke zero cigarettes per day when the value was missing. Individuals marked as current smokers with missing values were handled differently. To impute their value, the mean of cigarettes per day for all individuals who reported being a current smoker was utilized.\n"
      ],
      "metadata": {
        "id": "Tmw5ydasnA7p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **third variable** cleaned was ‘BPMeds’. This variable only had 37 missing values and had less significant positive correlation with ‘TenYearCHD’ than other similar variables within the dataset such as ‘diaBP’. Furthermore, so few individuals identified with this category (only around 3% of observations) that it was decided to impute all missing values with 0.\n"
      ],
      "metadata": {
        "id": "VGEcPajTnG2w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **fourth variable** cleaned was ‘totChol’. This variable also had very few missing values. On average this value was 236.0 mg/dL within patients with a standard deviation of 44.85 mg/dL. The slightly larger standard deviation than expected influenced us to impute the missing values with the median value of 233.0 mg/dL instead, although with both values being so close to one another this may not have been necessary."
      ],
      "metadata": {
        "id": "wp-1xnoxopQw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **fifth variable** cleaned was ‘BMI’. This variable had only a few missing values and as such the mean value was used to input the missing fields."
      ],
      "metadata": {
        "id": "qjasirjRo7RR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **final variable** cleaned was glucose. This variable had by far the most missing values of the dataset but proportionally they were still small to the size of the overall dataset (There were 285 out of 3180 total observations). Furthermore, the variable had a rather high standard deviation and an elevated positive correlated with the diabetes variable. Because the field is believed to be missing completely at random, it was decided that dropping the rows with missing values would not significantly alter the results of our model.\n"
      ],
      "metadata": {
        "id": "r9s35J29o-4L"
      }
    }
  ]
}