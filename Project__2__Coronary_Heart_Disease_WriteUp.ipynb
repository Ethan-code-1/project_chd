{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ethan-code-1/project_chd/blob/main/Project__2__Coronary_Heart_Disease_WriteUp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Summary**:"
      ],
      "metadata": {
        "id": "Jo8M3nuLY7TL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This paper hopes to showcase the likelihood of a person developing CHD based on specific factors to be able to establish what are the most significant factors that play into CHD. This is able to be accomplished via predictive models, specifically by seeing what variables allow for the predictive model to generate the highest accuracy. The dataset we used is a subset of data from the Framingham Heart Study which has data on a sample of patients. This data showcases important information about how the patient is in terms of health across various factors and how that corresponds to his 10 year CHD risk. For our method, in terms of predictive models, we could utilize linear models, k-nearest neighbors, or decision trees. We decided that we wanted to utilize decision trees as this is able to capture non-linear relationships between features and the target variable as well as make it easy to understand with the most important features being selected at each split. When fitting our decision tree and predicting it on our test set, we ended up achieving a predictive accuracy of 84% which was definitely the most optimal for us. From this, we were able to conclude that the factors that were the most significant predictors in CHD was age, glucose, TotChol, and CigsPerDay. This is important information as it helps the people understand what they need to focus on and be more aware of in order to minimize their risk of developing CHD."
      ],
      "metadata": {
        "id": "zFh8o7wem27u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data:**\n"
      ],
      "metadata": {
        "id": "BGezdaUUmu5y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To clean the data, a number of factors were taken into account. This process started by counting and displaying all the columns with missing values, as these values can cause errors within models and leave out important missing information. To begin, a correlation matrix was created to identify variables that are highly correlated with developing coronary heart disease according to the ‘TenYearCHD’ variable. In addition, external background research was also done to get an idea of the most important variables to consider. This helped guide the cleaning process and determine what data was and was not okay to loose. Some variables that stuck out as potentially being important at this point related to predominantly to age and blood pressure.\n",
        "\n",
        "\n",
        "Lastly, the describe method was used to get a general idea of the standard deviation of each variable which came in hand when deciding the best way to impute certain missing values (using the median vs mean for example).\n"
      ],
      "metadata": {
        "id": "dDYc8mAim9zg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **first variable** cleaned was education. This variable seemed to have a low negative correlation with the ‘TenYearCHD’ variable (the lowest of the variables present within the data). Due to this, and the relatively low number of missing values, all missing values were simply set to the mean for education field (the value ‘2’)."
      ],
      "metadata": {
        "id": "uBm3du15nAmw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "education_mean = df['education'].mean()\n",
        "print(education_mean)\n",
        "\n",
        "#Mean is essentially 2, so impute all missing values\n",
        "df['education'].fillna(2, inplace = True)"
      ],
      "metadata": {
        "id": "1bpQcjZXn6vU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **second variable** cleaned was ‘cigsPerDay’. This variable is heavily influenced by the ‘currentSmoker’ variable as individuals who do not smoke should have a value of zero for this field. As a result, all individuals with a ‘0’ for currentSmoker were also set to smoke zero cigarettes per day when the value was missing. Individuals marked as current smokers with missing values were handled differently. To impute their value, the mean of cigarettes per day for all individuals who reported being a current smoker was utilized.\n"
      ],
      "metadata": {
        "id": "Tmw5ydasnA7p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for index, row in df.iterrows():\n",
        "    if pd.isnull(row['cigsPerDay']):\n",
        "\n",
        "        if row['currentSmoker'] == 0:\n",
        "            df.at[index, 'cigsPerDay'] = 0\n",
        "        else:\n",
        "            df.at[index, 'cigsPerDay'] = 9"
      ],
      "metadata": {
        "id": "LMi796Lan7WZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **third variable** cleaned was ‘BPMeds’. This variable only had 37 missing values and had less significant positive correlation with ‘TenYearCHD’ than other similar variables within the dataset such as ‘diaBP’. Furthermore, so few individuals identified with this category (only around 3% of observations) that it was decided to impute all missing values with 0.\n"
      ],
      "metadata": {
        "id": "VGEcPajTnG2w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['BPMeds'].fillna(0, inplace = True)"
      ],
      "metadata": {
        "id": "4W_L8cGan7z0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **fourth variable** cleaned was ‘totChol’. This variable also had very few missing values. On average this value was 236.0 mg/dL within patients with a standard deviation of 44.85 mg/dL. The slightly larger standard deviation than expected influenced us to impute the missing values with the median value of 233.0 mg/dL instead, although with both values being so close to one another this may not have been necessary."
      ],
      "metadata": {
        "id": "wp-1xnoxopQw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['totChol'].median()\n",
        "df['totChol'].fillna(233.0, inplace = True)"
      ],
      "metadata": {
        "id": "od-V05Tfn8d_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **fifth variable** cleaned was ‘BMI’. This variable had only a few missing values and as such the mean value was used to input the missing fields."
      ],
      "metadata": {
        "id": "qjasirjRo7RR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['BMI'].mean()\n",
        "df['BMI'].fillna(25.89, inplace = True)"
      ],
      "metadata": {
        "id": "PkRnTFRFn8-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **final variable** cleaned was glucose. This variable had by far the most missing values of the dataset but proportionally they were still small to the size of the overall dataset (There were 285 out of 3180 total observations). Furthermore, the variable had a rather high standard deviation and an elevated positive correlated with the diabetes variable. Because the field is believed to be missing completely at random, it was decided that dropping the rows with missing values would not significantly alter the results of our model.\n"
      ],
      "metadata": {
        "id": "r9s35J29o-4L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(df['BPMeds'].mean())\n",
        "df['BPMeds'].fillna(0.03006993006993007, inplace = True)"
      ],
      "metadata": {
        "id": "Fg0LyKHOn9UK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}